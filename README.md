# Prompt-Engineering-using-LLMs
Phishing URL Detection with Prompt Engineering using Large Language Models

**Background**

Phishing attacks are a form of social engineering where attackers attempt to deceive victims into revealing sensitive information or clicking on malicious links and it remains a persistent threat in the digital landscape, causing significant financial losses and data breaches. Phishing has become increasingly sophisticated, making it challenging to distinguish legitimate URLs from fraudulent ones.
Recently, Large Language Models (LLMs) have been making significant impacts on various tasks including Machine Learning(ML) application development. These models are notable due to the use of vast amount of training datasets from diverse fields that the models are trained; and demonstrating impressive adaptability and performance across industries and regular human life.

This project aim to assess whether LLMs can provide a more efficient yet effective alternative to detect phishing URLs.
A new technique called prompt engineering which involves crafting specific input prompts to guide the LLM toward desired outputs without modifying the model itself can be utilized to detect phishing.


